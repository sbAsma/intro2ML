{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b24e36",
   "metadata": {},
   "source": [
    "# 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84969c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e2119",
   "metadata": {},
   "source": [
    "# 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4757dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has  5728  emails\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/spam classification 3 (csv)/Datasets/spam_normal_emails.csv\")\n",
    "print(\"The dataset has \", len(data), \" emails\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae5200",
   "metadata": {},
   "source": [
    "# 3. Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2eb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for text in data['text']:\n",
    "    cleaned_text = \"\"\n",
    "    for char in text:\n",
    "        if re.match(r\"([a-zA-Z])|([0-9])\", char) != None or char == \" \":\n",
    "            cleaned_text+=char.lower()\n",
    "    clean.append(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51b180",
   "metadata": {},
   "source": [
    "# 4. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6bfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [word_tokenize(x) for x in clean]\n",
    "# tokens = [word_tokenize(x) for x in clean]\n",
    "\n",
    "filtered_tokens = []\n",
    "en_stopwords = list(set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "# tokens that are not stopwords collected here\n",
    "for i in tokens:\n",
    "    filtered_tokens.append([])\n",
    "    for j in i:\n",
    "        if j in en_stopwords:\n",
    "            continue\n",
    "        else: filtered_tokens[-1].append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8c0d7",
   "metadata": {},
   "source": [
    "# 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c0ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Lancaster Stemmer\n",
    "LS = LancasterStemmer()\n",
    "stemmed_words = []\n",
    "for l in filtered_tokens: stemmed_words.append([LS.stem(w) for w in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f2e7a",
   "metadata": {},
   "source": [
    "# 6. Generating words occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d3ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [i for sublist in stemmed_words for i in sublist]\n",
    "\n",
    "flat_list_reduced = list(set(flat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d13f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stemmed_words = pd.DataFrame(columns = flat_list_reduced, index=np.arange(len(stemmed_words)))\n",
    "index=0\n",
    "for sequence in stemmed_words:\n",
    "    words_in_seq = [sequence.count(word) for word in flat_list_reduced]\n",
    "    data_stemmed_words.iloc[index] = words_in_seq\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50bcda",
   "metadata": {},
   "source": [
    "# 7. Preparing the train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d157726",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(data_stemmed_words.values)\n",
    "y = data[\"spam\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c782ac",
   "metadata": {},
   "source": [
    "# 8. SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388b341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  96.04 %\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = SVC(kernel='linear')\n",
    "classifier_linear.fit(X_train, y_train)\n",
    "prediction_linear = classifier_linear.predict(X_test)\n",
    "acc = accuracy_score(y_test, prediction_linear)*100\n",
    "print(\"acc = \", \"{:.2f}\".format(acc), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
